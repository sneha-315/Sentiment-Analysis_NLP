{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8618787,"sourceType":"datasetVersion","datasetId":5158848},{"sourceId":8619215,"sourceType":"datasetVersion","datasetId":5159181}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-06T06:17:52.597520Z","iopub.execute_input":"2024-06-06T06:17:52.598063Z","iopub.status.idle":"2024-06-06T06:17:52.618629Z","shell.execute_reply.started":"2024-06-06T06:17:52.598027Z","shell.execute_reply":"2024-06-06T06:17:52.616896Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/sentiment140-csv/training.1600000.processed.noemoticon.csv\n/kaggle/input/glove-dataset/glove.6B.100d.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import precision_score, recall_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:22:26.975621Z","iopub.execute_input":"2024-06-06T11:22:26.976015Z","iopub.status.idle":"2024-06-06T11:22:26.982520Z","shell.execute_reply.started":"2024-06-06T11:22:26.975981Z","shell.execute_reply":"2024-06-06T11:22:26.981069Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"nltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:22:34.982681Z","iopub.execute_input":"2024-06-06T11:22:34.983064Z","iopub.status.idle":"2024-06-06T11:22:55.032428Z","shell.execute_reply.started":"2024-06-06T11:22:34.983034Z","shell.execute_reply":"2024-06-06T11:22:55.031147Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sentiment140-csv/training.1600000.processed.noemoticon.csv', encoding='latin1')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:23:05.681701Z","iopub.execute_input":"2024-06-06T11:23:05.682091Z","iopub.status.idle":"2024-06-06T11:23:12.947765Z","shell.execute_reply.started":"2024-06-06T11:23:05.682059Z","shell.execute_reply":"2024-06-06T11:23:12.946644Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n\n  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n0  is upset that he can't update his Facebook by ...                                                                   \n1  @Kenichan I dived many times for the ball. Man...                                                                   \n2    my whole body feels itchy and like its on fire                                                                    \n3  @nationwideclass no, it's not behaving at all....                                                                   \n4                      @Kwesidei not the whole crew                                                                    ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1467810369</th>\n      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n      <th>NO_QUERY</th>\n      <th>_TheSpecialOne_</th>\n      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811372</td>\n      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ndf.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:23:34.035035Z","iopub.execute_input":"2024-06-06T11:23:34.035466Z","iopub.status.idle":"2024-06-06T11:23:34.041122Z","shell.execute_reply.started":"2024-06-06T11:23:34.035431Z","shell.execute_reply":"2024-06-06T11:23:34.039951Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df = df[['target', 'text']]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:23:36.655593Z","iopub.execute_input":"2024-06-06T11:23:36.656020Z","iopub.status.idle":"2024-06-06T11:23:36.708950Z","shell.execute_reply.started":"2024-06-06T11:23:36.655987Z","shell.execute_reply":"2024-06-06T11:23:36.707816Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df['target'] = df['target'].map({0: 0, 4: 1})","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:23:39.239072Z","iopub.execute_input":"2024-06-06T11:23:39.239499Z","iopub.status.idle":"2024-06-06T11:23:39.279175Z","shell.execute_reply.started":"2024-06-06T11:23:39.239466Z","shell.execute_reply":"2024-06-06T11:23:39.277987Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    text = text.lower()  # Convert to lowercase\n    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n    text = re.sub(r'\\d+', '', text)  # Remove numbers\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    text = text.strip()  # Remove leading/trailing whitespace\n    stop_words = set(stopwords.words('english'))\n    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n    return text\n\ndf['clean_text'] = df['text'].apply(preprocess_text)\n\n# Encode the target labels (0 for negative, 4 for positive)\nlabel_encoder = LabelEncoder()\ndf['target'] = label_encoder.fit_transform(df['target'])\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['target'], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:23:41.591750Z","iopub.execute_input":"2024-06-06T11:23:41.592155Z","iopub.status.idle":"2024-06-06T11:28:26.579052Z","shell.execute_reply.started":"2024-06-06T11:23:41.592122Z","shell.execute_reply":"2024-06-06T11:28:26.577861Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"embeddings_index = {}\nwith open('/kaggle/input/glove-dataset/glove.6B.100d.txt', encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs\n\nprint(f\"Loaded {len(embeddings_index)} word vectors.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:29:02.235460Z","iopub.execute_input":"2024-06-06T11:29:02.235869Z","iopub.status.idle":"2024-06-06T11:29:17.165379Z","shell.execute_reply.started":"2024-06-06T11:29:02.235838Z","shell.execute_reply":"2024-06-06T11:29:17.164037Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Loaded 400000 word vectors.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train)\nword_index = tokenizer.word_index\n\n\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)\n\n\nmax_seq_length = 100\nX_train_pad = pad_sequences(X_train_seq, maxlen=max_seq_length)\nX_test_pad = pad_sequences(X_test_seq, maxlen=max_seq_length)\n\n\nembedding_dim = 100\nembedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:30:03.100162Z","iopub.execute_input":"2024-06-06T11:30:03.101218Z","iopub.status.idle":"2024-06-06T11:31:20.057495Z","shell.execute_reply.started":"2024-06-06T11:30:03.101121Z","shell.execute_reply":"2024-06-06T11:31:20.056255Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"2024-06-06 11:30:05.398616: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-06 11:30:05.398849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-06 11:30:05.579243: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=len(word_index) + 1, \n                    output_dim=embedding_dim, \n                    weights=[embedding_matrix], \n                    input_length=max_seq_length, \n                    trainable=False))\nmodel.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n\nmodel.fit(X_train_pad, y_train, epochs=5, batch_size=128, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:34:37.569246Z","iopub.execute_input":"2024-06-06T11:34:37.570023Z","iopub.status.idle":"2024-06-06T13:51:03.784895Z","shell.execute_reply.started":"2024-06-06T11:34:37.569990Z","shell.execute_reply":"2024-06-06T13:51:03.783270Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1632s\u001b[0m 204ms/step - accuracy: 0.7198 - loss: 0.5436 - val_accuracy: 0.7716 - val_loss: 0.4727\nEpoch 2/5\n\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1631s\u001b[0m 204ms/step - accuracy: 0.7649 - loss: 0.4832 - val_accuracy: 0.7805 - val_loss: 0.4599\nEpoch 3/5\n\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1647s\u001b[0m 206ms/step - accuracy: 0.7739 - loss: 0.4697 - val_accuracy: 0.7818 - val_loss: 0.4565\nEpoch 4/5\n\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1632s\u001b[0m 204ms/step - accuracy: 0.7783 - loss: 0.4631 - val_accuracy: 0.7856 - val_loss: 0.4507\nEpoch 5/5\n\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1642s\u001b[0m 205ms/step - accuracy: 0.7801 - loss: 0.4588 - val_accuracy: 0.7850 - val_loss: 0.4515\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x78276d7e1600>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\n\ny_pred = model.predict(X_test_pad)\ny_pred = (y_pred > 0.5).astype(int)\n\n\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(f\"Precision: {precision:.2f}\")\nprint(f\"Recall: {recall:.2f}\")\nprint(f\"F1 Score: {f1:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T13:51:17.691182Z","iopub.execute_input":"2024-06-06T13:51:17.691638Z","iopub.status.idle":"2024-06-06T13:57:57.462479Z","shell.execute_reply.started":"2024-06-06T13:51:17.691605Z","shell.execute_reply":"2024-06-06T13:57:57.461211Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 39ms/step\nPrecision: 0.77\nRecall: 0.82\nF1 Score: 0.79\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}